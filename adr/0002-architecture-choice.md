# 2. Почему мы выбрали такую архитектуру

Date: 2025-11-29

## Status

Accepted

## Context

Нужно сделать воспроизводимый DevOps-проект, который включает:
- HTTP API с health-эндами и ML-инференсом.
- ML-пайплайн с обучением, логированием метрик (MLflow) и отчётами по дрейфу/качеству (Deepchecks/Evidently).
- Автоматизированное развёртывание и инфраструктуру как код.
- Нагрузочное тестирование через Locust и healthchecks в контейнерах.

Ограничения:
- Должно подниматься «с нуля» на любой машине/CI.
- Должно быть переносимо в облако/serverless или локальный Docker.
- Должны быть явные точки входа для тестов и мониторинга.

## Decision

Выбираем контейнерную архитектуру с разделением ответственности:
- FastAPI-сервис в отдельном Docker-образе (`/health`, `/healthz`, `/predict`).
- ML-пайплайн отдельным скриптом (`src/train.py`), который готовит модель и отчёты, запускается в CI.
- IaC через Terraform для serverless-контейнера в Яндексе (опционально) и Docker Compose для локальных запусков.
- CI (GitHub/GitLab) гоняет обучение и публикует артефакты; при необходимости добавляем сборку образа.
- Locust-сценарий бьёт по HTTP API для нагрузочного теста.

## Consequences

Плюсы:
- Воспроизводимость через Docker и зафиксированные зависимости.
- Чёткие контракты: эндпоинты API, путь до артефакта модели, healthchecks для рантайма.
- Готово к CI: обучение и артефакты не зависят от состояния хоста.
- Портируемо: один образ работает локально, в CI и в serverless/контейнерных платформах.

Минусы/риски:
- Выше начальная сложность (Docker, Terraform, CI) по сравнению с одним скриптом.
- Нужно хранить и защищать секреты (токены реестра, облачные ключи) вне репозитория.
- Двухшаговый процесс (сначала train, потом serve) требует следить за актуальностью модели.

Рассмотренные альтернативы:
- Монолитный Python-скрипт без контейнеров/CI/IaC (проще, но не воспроизводим и труднее переносим).
- Чистая serverless-функция без контейнерного реестра (меньше контроля над зависимостями и healthchecks).
